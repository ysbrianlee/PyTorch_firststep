{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_chapter3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"wGFZ2dlWewtt","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install http://download.pytorch.org/whl/cu90/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n","!pip install torchvision\n","!pip install tqdm\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bELyfJg4zWRR","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from torch import nn\n","\n","net = nn.Sequential(\n","    nn.Linear(64, 32),\n","    nn.ReLU(),\n","    nn.Linear(32, 16),\n","    nn.ReLU(),\n","    nn.Linear(16, 10)\n",")\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b5ZUgKhB7sjk","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch import optim\n","from sklearn.datasets import load_digits\n","digits = load_digits()\n","\n","X = digits.data\n","Y = digits.target\n","\n","# NumPy의 ndarray를 PyTorch의 Tensor로 변환\n","X = torch.tensor(X, dtype=torch.float32)\n","Y = torch.tensor(Y, dtype=torch.int64)\n","\n","# 소프트맥스 크로스 엔트로피\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Adam\n","optimizer = optim.Adam(net.parameters())\n","\n","# 손실 함수의 로그\n","losses = []\n","\n","# 100회 반복\n","for epoc in range(100):\n","     # backward 메서드로 계산된 \n","    #이전 값을 삭제\n","    optimizer.zero_grad()\n","    \n","    # 선형 모델로 y의 예측 값 계산\n","    y_pred = net(X)\n","    \n","    # MSE loss와 w를 사용한 미분 계산\n","    loss = loss_fn(y_pred, Y)\n","    loss.backward()\n","    \n","    # 경사를 갱신\n","    optimizer.step()\n","    \n","    # 수렴 확인을 위해 loss를 기록해둔다\n","    losses.append(loss.item())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hwFS36dX8rSh","colab_type":"code","outputId":"46e64553-ea56-48fc-84f9-e50d92c8a010","executionInfo":{"status":"ok","timestamp":1545978895684,"user_tz":-480,"elapsed":756,"user":{"displayName":"winston kim","photoUrl":"","userId":"05942964544969189760"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"cell_type":"code","source":["X = X.to(\"cuda:0\")\n","Y = Y.to(\"cuda:0\")\n","net.to(\"cuda:0\")\n","\n","# 이후 처리는 동일하게 optimizer를 설정해서 학습 루프를 돌린다"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=64, out_features=32, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=32, out_features=16, bias=True)\n","  (3): ReLU()\n","  (4): Linear(in_features=16, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"OKJz-w21FrBE","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","\n","# Dataset 작성\n","ds = TensorDataset(X, Y)\n","\n","# 순서로 섞어서 64개씩 데이터를 반환하는 DataLoader 작성\n","loader = DataLoader(ds, batch_size=64, shuffle=True)\n","\n","net = nn.Sequential(\n","    nn.Linear(64, 32),\n","    nn.ReLU(),\n","    nn.Linear(32, 16),\n","    nn.ReLU(),\n","    nn.Linear(16, 10)\n",")\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters())\n","\n","# 최적화 실행\n","losses = []\n","for epoch in range(10):\n","    running_loss = 0.0\n","    for xx, yy in loader:\n","        # xx, yy는 64개만는다\n","        y_pred = net(xx)\n","        loss = loss_fn(y_pred, yy)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    losses.append(running_loss)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cXfXTxxRQMm4","colab_type":"code","colab":{}},"cell_type":"code","source":["#데이터를 훈령용과 검증용으로 분할\n","from sklearn.model_selection import train_test_split\n","# 전체의 30%는 검증용\n","X = digits.data\n","Y = digits.target\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","Y_train = torch.tensor(Y_train, dtype=torch.int64)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","Y_test = torch.tensor(Y_test, dtype=torch.int64)\n","\n","# 여러 층을 쌓아서 깊은 신경망을 구축한다\n","k = 100\n","net = nn.Sequential(\n","    nn.Linear(64, k),\n","    nn.ReLU(),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.Linear(k, 10)\n",")\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters())\n","# 훈련용 데이터로 DataLoader를 작성\n","ds = TensorDataset(X_train, Y_train)\n","loader = DataLoader(ds, batch_size=32, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"foudr4_ZRTec","colab_type":"code","colab":{}},"cell_type":"code","source":["train_losses = []\n","test_losses = []\n","for epoch in range(100):\n","    running_loss = 0.0\n","    for i, (xx, yy) in enumerate(loader):\n","        y_pred = net(xx)\n","        loss = loss_fn(y_pred, yy)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    train_losses.append(running_loss / i)\n","    y_pred = net(X_test)\n","    test_loss = loss_fn(y_pred, Y_test)\n","    test_losses.append(test_loss.item())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CaTqA_7SSh1f","colab_type":"code","colab":{}},"cell_type":"code","source":["# 확률 0.5로 랜덤으로 변수의 차원을\n","# 버리는 Dropout을 각 층에 추가\n","net = nn.Sequential(\n","    nn.Linear(64, k),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(k, 10)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n2hhGcc7TEVv","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optim.Adam(net.parameters())\n","\n","train_losses = []\n","test_losses = []\n","for epoch in range(100):\n","    running_loss = 0.0\n","    # 신경망을 훈련 모드로 설정\n","    net.train()\n","    for i, (xx, yy) in enumerate(loader):\n","        y_pred = net(xx)\n","        loss = loss_fn(y_pred, yy)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    train_losses.append(running_loss / i)\n","    # 신경망을 평가 모드로 설정하고\n","    # 검증 데이터의 손실 함수를 계산\n","    net.eval()\n","    y_pred = net(X_test)\n","    test_loss = loss_fn(y_pred, Y_test)\n","    test_losses.append(test_loss.item())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sPUpNv3Dd2kd","colab_type":"code","colab":{}},"cell_type":"code","source":["# Linear층에는 BatchNorm1d를 적용한다\n","net = nn.Sequential(\n","    nn.Linear(64, k),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(k),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(k),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(k),\n","    nn.Linear(k, k),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(k),\n","    nn.Linear(k, 10)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gQfRQDu60JuZ","colab_type":"code","colab":{}},"cell_type":"code","source":["class CustomLinear(nn.Module):\n","    def __init__(self, in_features,\n","                  out_features,\n","                  bias=True, p=0.5):\n","        super().__init__()\n","        self.linear = nn.Linear(in_features,\n","                                out_features,\n","                                bias)\n","        self.relu = nn.ReLU()\n","        self.drop = nn.Dropout(p)\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","        x = self.relu(x)\n","        x = self.drop(x)\n","        return x\n","      \n","mlp = nn.Sequential(\n","    CustomLinear(64, 200),\n","    CustomLinear(200, 200),\n","    CustomLinear(200, 200),\n","    nn.Linear(200, 10)\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4fciRX3Q1_om","colab_type":"code","colab":{}},"cell_type":"code","source":["class MyMLP(nn.Module):\n","    def __init__(self, in_features,\n","                  out_features):\n","        super().__init__()\n","        self.ln1 = CustomLinear(in_features, 200)\n","        self.ln2 = CustomLinear(200, 200)\n","        self.ln3 = CustomLinear(200, 200)\n","        self.ln4 = CustomLinear(200, out_features)\n","    \n","    def forward(self, x):\n","        x = self.ln1(x)\n","        x = self.ln2(x)\n","        x = self.ln3(x)\n","        x = self.ln4(x)\n","        return x\n","      \n","mlp = MyMLP(64, 10)"],"execution_count":0,"outputs":[]}]}